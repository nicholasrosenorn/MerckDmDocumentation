[
["index.html", "Wearables Book Chapter 1 Book Overview", " Wearables Book Merck and Data Mine Corporate Partnership Team 2020-06-16 Chapter 1 Book Overview A foundation of knowledge in the data sciences can prove advantageous for almost all scientists. Often, however, understanding the fundamentals of any new skill lacking proper instruction or recourses can be difficult. With ample guidance, all can develop a base knowledge of Data Science that can grow and provide new skills for improved research experiences. The sets of instruction, examples, and tutorials in this walk-through are specifically designed for Merck Technology and can be distributed to Merck Scientists. The walk-through will be tailored to the needs of the pharmaceutical industry and will relate to work being done at Merck. In this walkthrough, a complete, end-to-end, project will be outlined with instructional and applicational opportunities throughout. "],
["intro.html", "Chapter 2 Data Science Overview", " Chapter 2 Data Science Overview Data Science is an interdisciplinary field aimed to extract insight from structured and unstructured data. An intersection between computing, statistics, mathematics, and domain application, data science reveals new meaning to the extreme amounts of data being collected and stored every day. Some of the foundational skills that the data sciences require include basic computing and data analysis knowledge. A range of technologies are used daily by data scientists, including Python, R, Hadoop, Bash, and more. Statistical concepts like descriptive statistics, probability, Bayesian theory, and modeling are used in combination with the previously mentioned technologies to gain insight from data. "],
["project-introduction.html", "Chapter 3 Project Introduction", " Chapter 3 Project Introduction An end-to-end project will be outlined in the remainder of the text. Primary concepts included are data capture, data visualization, and client-server communication. The technologies covered will include Python, Bash, SQL, R, and React Native along with many useful packages and dependencies. Throughout each section of the text, there will be an introduction to a new technology. Basic programming skills and logic explanation related to the technology will be covered within this section. Using the skills taught, the walkthrough section will follow, where instruction related to the overall project will be given. The project being taught in this text is a data capture project that will evolve into a basic mobile application. Using Fitbit technology, users are collecting massive amounts of biometric data that, if captured properly, can be used to benefit pharmaceutical research. Patient activity, heart, sleep, and weight data can all be captured seamlessly. The medicinal benefits are great with a tool like this. It is through simple computing and foundational data science topics that a pipeline and tool can be engineered. "],
["merck-technology.html", "Chapter 4 Merck Technology", " Chapter 4 Merck Technology "],
["fitbit-technology.html", "Chapter 5 Fitbit Technology", " Chapter 5 Fitbit Technology To begin the project, we will begin by discussing application programming interfaces (API). APIs are tools that allow developers to begin work easily. Often times, an API is a set of functions or methods that allow for replication of previously developed services. When released publicly, APIs allow for developers to gain access easily to features and data of large services. The API that this walk-through works with is the Fitbit Web API. The API can be found at https://dev.fitbit.com/build/reference/web-api/basics/ and the accompanying documentation can be found at https://python-fitbit.readthedocs.io/en/latest/. The first step to using the Fitbit API is to create a Fitbit account. Creating a new account can be found at https://accounts.fitbit.com/signup. You will be presented with the screen show below. Simply, enter an email and password of choice to create an account. You do not have to associate a Fitbit device to complete this tutorial. While no personal data will be collected due to lack of a device, the walk-through will still cover how properly use the API to access data. When data is necessary for later in the tutorial, dummy data will be provided. After registering your Fitbit account, proceed to https://dev.fitbit.com/login and login with the account credentials you just created. Click on ‘manage’ and ‘register an app’ in the navigation bar. You will then be presented with the screen show in figure 2. Fill out the necessary registration fields and click ‘register’ at the bottom of the page. Now that an application is registered to your account, you can navigate to your apps. When clicking on the recently created app you will see a samilar display as in Figure 3. The creation and registration of this app with fitbit will be neccessary for the entirity of the tutorial. We will return to the information shown soon. "],
["dependencies.html", "Chapter 6 Dependencies", " Chapter 6 Dependencies For this project, it will be easiest for work in an Anaconda enirvonement. Anaconda is an open-source Data Science toolkit. It allows users to easily work with thousands of open-source packages. Install Anaconda here: https://docs.anaconda.com/anaconda/install/. Follow the steps provided to install for your machine. After you have installed Anaconda, open the Anaconda Navigator. It will look similar to the image below. On the left side navigation bar, click on evironments and then search for ‘cherrypy’. —– Open Jupyter notebook description —— knitr::opts_chunk$set(echo = TRUE) "],
["working-in-python.html", "Chapter 7 Working in Python 7.1 Python Introduction 7.2 Reading Data, Conditionals, Loops 7.3 Pandas and Numpy 7.4 Vizualizations with Matplotlib", " Chapter 7 Working in Python knitr::opts_chunk$set(echo = TRUE, engine.path = list(python = ‘/Library/Frameworks/Python.framework/Versions/3.7/bin/python3’)) In this section, we will cover important computing fundamtentals using the python programming language. These fundamentals are transferrable between many programming languages so laying a strong foundation will prove benfeficial. If you are new to python, it is in your best interest to review some of the matieral at https://www.w3schools.com/python/ for foundational skills. 7.1 Python Introduction Python is an interpreted programming language that is known for its simplicity, readability, and small learning curve. Python is one of the most popular programming languages used today and learning to use Python will provide fundamental computing skills. For this tutorial, it is easiest to use a Jupyter Notebook. Create a new notebook and select Python as the language. Before starting the tutorial, add the follow imports at the top of your notebook: # These are helpful packages that will aid our work through the tutorial! import sys import csv import requests from collections import defaultdict 7.2 Reading Data, Conditionals, Loops The data for this tutorial can be found at https://raw.githubusercontent.com/fivethirtyeight/data/master/us-weather-history/KNYC.csv. The data is in CSV format meaning that each new value is seperated by a comma. Take a look at the raw data by visiting the link. It is data on weather patterns in NYC during parts of 2014 and 2015. Now that we know the format of the data, lets read it into our Notebook. # open the file directly from the link file = requests.get(&quot;https://raw.githubusercontent.com/fivethirtyeight/data/master/us-weather-history/KNYC.csv&quot;).text Right now, the file is a string. To work with our data, we need to clean it and get it to a format for better analysis. To start, we will need to remove any unneccessary whitespace and create a list where each element is a new line. # strip() - method that removes whitespace # split(&quot;\\n&quot;) - method that returns a list of values broken by input characters from the input string. file = file.strip().split(&#39;\\n&#39;) Our file is now a list, where each element is one row (run print(file) if you would like to check). Our objective is to make each element of the list, a new list! We can easily do this using a for loop. A for loop will iterate over a sequence (i.e lists, dictionaries, tuples, sets) and perform itertive commands in the loop. Lets try to clean our data some more. # for each element of the list, split the element by comma to make sublists for row in range(len(file)): file[row] = file[row].split(&quot;,&quot;) Great, our data is cleaned! Let’s view our file with a loop: # Print the first five file lines of the data for row in file[0:5]: print(row) ## [&#39;date&#39;, &#39;actual_mean_temp&#39;, &#39;actual_min_temp&#39;, &#39;actual_max_temp&#39;, &#39;average_min_temp&#39;, &#39;average_max_temp&#39;, &#39;record_min_temp&#39;, &#39;record_max_temp&#39;, &#39;record_min_temp_year&#39;, &#39;record_max_temp_year&#39;, &#39;actual_precipitation&#39;, &#39;average_precipitation&#39;, &#39;record_precipitation&#39;] ## [&#39;2014-7-1&#39;, &#39;81&#39;, &#39;72&#39;, &#39;89&#39;, &#39;68&#39;, &#39;83&#39;, &#39;52&#39;, &#39;100&#39;, &#39;1943&#39;, &#39;1901&#39;, &#39;0.00&#39;, &#39;0.12&#39;, &#39;2.17&#39;] ## [&#39;2014-7-2&#39;, &#39;82&#39;, &#39;72&#39;, &#39;91&#39;, &#39;68&#39;, &#39;83&#39;, &#39;56&#39;, &#39;100&#39;, &#39;2001&#39;, &#39;1966&#39;, &#39;0.96&#39;, &#39;0.13&#39;, &#39;1.79&#39;] ## [&#39;2014-7-3&#39;, &#39;78&#39;, &#39;69&#39;, &#39;87&#39;, &#39;68&#39;, &#39;83&#39;, &#39;54&#39;, &#39;103&#39;, &#39;1933&#39;, &#39;1966&#39;, &#39;1.78&#39;, &#39;0.12&#39;, &#39;2.80&#39;] ## [&#39;2014-7-4&#39;, &#39;70&#39;, &#39;65&#39;, &#39;74&#39;, &#39;68&#39;, &#39;84&#39;, &#39;55&#39;, &#39;102&#39;, &#39;1986&#39;, &#39;1949&#39;, &#39;0.14&#39;, &#39;0.13&#39;, &#39;1.76&#39;] Notice that the first line is the header line and the rest of the lines are data for the corresponding headers. Let’s take a look at the maximum temperature on the first five days listed in the data set. for row in file[0:6]: print(&quot;%-20s %s&quot; % (row[0],row[3])) # simple string formatting techniques! ## date actual_max_temp ## 2014-7-1 89 ## 2014-7-2 91 ## 2014-7-3 87 ## 2014-7-4 74 ## 2014-7-5 81 7.3 Pandas and Numpy While our data is already organized well, more complex analysis with data in this format can get tedious. A popular data maniputlation and analysis software is called Pandas. Let’s explore the functionality of Pandas! To start, let’s create the list of headers: headers = file[0] headers ## [&#39;date&#39;, &#39;actual_mean_temp&#39;, &#39;actual_min_temp&#39;, &#39;actual_max_temp&#39;, &#39;average_min_temp&#39;, &#39;average_max_temp&#39;, &#39;record_min_temp&#39;, &#39;record_max_temp&#39;, &#39;record_min_temp_year&#39;, &#39;record_max_temp_year&#39;, &#39;actual_precipitation&#39;, &#39;average_precipitation&#39;, &#39;record_precipitation&#39;] Next, we will reformat our original list of data so that the headers are removed: import datetime data = file[1:] # remove header for row in data: # convert data from strings to floats for i in range(0,13): if i == 0: row[i]= datetime.datetime.strptime(row[i],&#39;%Y-%m-%d&#39;) else: row[i] = float(row[i]) Lastly, we will place our data into a pandas dataframe: import pandas as pd df = pd.DataFrame(data, columns = headers) df.head() # .head() is a way to view the first 5 rows of the dataframe ## date actual_mean_temp ... average_precipitation record_precipitation ## 0 2014-07-01 81.0 ... 0.12 2.17 ## 1 2014-07-02 82.0 ... 0.13 1.79 ## 2 2014-07-03 78.0 ... 0.12 2.80 ## 3 2014-07-04 70.0 ... 0.13 1.76 ## 4 2014-07-05 72.0 ... 0.12 3.07 ## ## [5 rows x 13 columns] Great! Now we can perfom analysis very easily on our data! For example, we can find some very valuable statistics with one simple command! df.describe() ## actual_mean_temp ... record_precipitation ## count 365.000000 ... 365.000000 ## mean 54.736986 ... 2.386137 ## std 18.679979 ... 1.045702 ## min 11.000000 ... 0.860000 ## 25% 39.000000 ... 1.690000 ## 50% 58.000000 ... 2.160000 ## 75% 72.000000 ... 2.750000 ## max 85.000000 ... 8.280000 ## ## [8 rows x 12 columns] Pandas is a very poweful tool! More about pandas can be learned at https://pandas.pydata.org/pandas-docs/version/0.25.3/. 7.4 Vizualizations with Matplotlib Lastly, we can make a simple vizualization of our data using another package called Matplotlib. It is a plotting library for the python programming langauge. import matplotlib.pyplot as plt fig, ax = plt.subplots(figsize=(12, 12)) y =df[&#39;actual_max_temp&#39;] x=df[&#39;date&#39;] ax.plot(x,y) ax.set(xlabel=&quot;Date&quot;, ylabel=&quot;Max Temp (F)&quot;, title=&quot;Max Temperarure in New York City&quot;) ## [Text(0, 0.5, &#39;Max Temp (F)&#39;), Text(0.5, 0, &#39;Date&#39;), Text(0.5, 1.0, &#39;Max Temperarure in New York City&#39;)] plt.gcf().autofmt_xdate() plt.show() Matplot has much more funtionality than this simple example. Refer to the documentation at https://matplotlib.org/3.2.1/contents.html for more information! "],
["tutorial-data-capture-in-python.html", "Chapter 8 Tutorial - Data Capture in Python 8.1 Getting Started 8.2 Imports 8.3 Authentication 8.4 Accessing Data 8.5 Processing Data 8.6 Storing Data", " Chapter 8 Tutorial - Data Capture in Python 8.1 Getting Started Before starting this section of the tutorial, we need to download the Fitbit API. Navigate to https://github.com/orcasgit/python-fitbit and click the green ‘clone or download’ button. Then, click download zip, and open the zip file in the same folder that you are using within Anaconda. Next, download python on to your computer at https://www.python.org/downloads/. Click on the yellow ‘download’ button, open the downloaded file, and follow the steps to install. Lastly, open a new terminal, and run the following commands: pip install cherrypy (you can also use the Anaconda navigator to install cherrypy) pip install requests-oauthlib 8.2 Imports This project requires multiple packages. If the steps in the previous sections have been followed, these import statements should run seamlessly. #Import the necessary packages import fitbit import gather_keys_oauth2 as Oauth2 import pandas as pd import datetime import json 8.3 Authentication Remembering back to the Fibit Technology section, we registered an app on the Fitbit Development site that will allow us to access our account data. When we completed the registration of the app, we were given a client id and client secret. These codes are unique to each individual app that is registered and are neccessary for the authentication process. Use the following code gain access to your account: CLIENT_ID = &#39;22BLXS&#39; #ENTER CLIENT ID CODE HERE CLIENT_SECRET = &#39;a259368e5736a4171753dba8133f06d4&#39; #ENTER CLIENT SECRET CODE HERE server = Oauth2.OAuth2Server(CLIENT_ID, CLIENT_SECRET) server.browser_authorize() ACCESS_TOKEN = str(server.fitbit.client.session.token[&#39;access_token&#39;]) REFRESH_TOKEN = str(server.fitbit.client.session.token[&#39;refresh_token&#39;]) auth2_client = fitbit.Fitbit(CLIENT_ID, CLIENT_SECRET, oauth2=True, access_token=ACCESS_TOKEN, refresh_token=REFRESH_TOKEN) When the code above is run for the first time, you will be directed to a new browser with the following screen: Select ‘Allow All’ and then ‘Allow’. Your browser will then display the follow: When you have reached this screen, the authentication is complete and you can now access your account data. According the fitbit documentation, you can access your data, by default, for 8 hours until you will have to reautheticate by running the authorization code above. 8.4 Accessing Data Now that the authentication is complete, we can access our data. To start, we need to delcare a date to collect data from. Let’s use today’s date: today = str(datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;)) #todays date Now we can view our ‘activities’ data for todays date. activities = auth2_client.activities(date = today) Notice how the data is formatted in nested dictionary format, similar to json file format. Becuase of this format, we need to decompose the nested dictionaries to access our desired data. For example, if we want to access the total distance traveled we can do the following: activities = auth2_client.activities(date = today)[&#39;summary&#39;] totalDistance = activities[&#39;distances&#39;][0][&#39;distance&#39;] To access today’s steps: steps = activities[&#39;steps&#39;] The process is almost identical for accessing other types of data (i.e. sleep, heart, and weight data). 8.5 Processing Data Because we are now familiar with the structure of of data, we can begin processing it! To collect activities data: #gets all Activities Data def getActivities(myDate): activities = auth2_client.activities(date = myDate)[&#39;summary&#39;] totalDistance = activities[&#39;distances&#39;][0][&#39;distance&#39;] veryActiveDistance = activities[&#39;distances&#39;][3][&#39;distance&#39;] moderatleyActiveDistance = activities[&#39;distances&#39;][4][&#39;distance&#39;] lightlyActiveDistance = activities[&#39;distances&#39;][5][&#39;distance&#39;] veryActiveMinutes = activities[&#39;veryActiveMinutes&#39;] fairlyActiveMinutes = activities[&#39;fairlyActiveMinutes&#39;] lightlyActiveMinutes = activities[&#39;lightlyActiveMinutes&#39;] sedentaryMinutes = activities[&#39;sedentaryMinutes&#39;] floorsClimbed = activities[&#39;floors&#39;] daySteps =activities[&#39;steps&#39;] return totalDistance, veryActiveDistance, moderatleyActiveDistance, lightlyActiveDistance, veryActiveMinutes, fairlyActiveMinutes, lightlyActiveMinutes, sedentaryMinutes, floorsClimbed, daySteps To collect sleep data: #gets all Sleep data def getSleep(myDate): nightSleep = auth2_client.sleep(date = myDate)[&#39;sleep&#39;] sleepEfficiency = None minutesAsleep = None if len(nightSleep) != 0: sleepEfficiency = nightSleep[0][&#39;efficiency&#39;] minutesAsleep = nightSleep[0][&#39;minutesAsleep&#39;] return sleepEfficiency, minutesAsleep To collect heart data: #gets all Heart Data def getHeart(myDate): heartRates = auth2_client.intraday_time_series(&#39;activities/heart&#39;, base_date=myDate, detail_level=&#39;1sec&#39;)[&#39;activities-heart&#39;][0][&#39;value&#39;] HRrange30to100 = None HRrange100to140 = None HRrange140to170 = None HRrange170to220 = None avgRestingHR = None if len(heartRates) == 3: HRrange30to100 = heartRates[&#39;heartRateZones&#39;][0][&#39;minutes&#39;] HRrange100to140 = heartRates[&#39;heartRateZones&#39;][1][&#39;minutes&#39;] HRrange140to170 = heartRates[&#39;heartRateZones&#39;][2][&#39;minutes&#39;] HRrange170to220 = heartRates[&#39;heartRateZones&#39;][3][&#39;minutes&#39;] avgRestingHR = heartRates[&#39;restingHeartRate&#39;] return HRrange30to100, HRrange100to140, HRrange140to170, HRrange170to220, avgRestingHR To collect weight data: #gets all Weight Data def getWeight(myDate): grabWeight = auth2_client.get_bodyweight(base_date = myDate)[&#39;weight&#39;] weight = None BMI = None if len(grabWeight) &gt; 0: weight = grabWeight[0][&#39;weight&#39;] BMI = grabWeight[0][&#39;bmi&#39;] return weight, BMI Now that we have the functions to capture the data, we can process our data with a pandas data frame: #creates empty data frame biometricDF = pd.DataFrame(columns=[&quot;Date&quot;, &quot;Steps&quot;, &quot;Floors Climbed&quot;, &quot;Total Miles&quot;, &quot;Lightly Active Miles&quot;, &quot;Moderately Active Miles&quot;, &quot;Very Active Miles&quot;, &quot;Sedentary Minutes&quot;, &quot;Lightly Active Minutes&quot;, &quot;Fairly Active Minutes&quot;, &quot;Very Active Minutes&quot;, &quot;HR 30-100 Minutes&quot;, &quot;HR 100-140 Minutes&quot;, &quot;HR 140-170 Minutes&quot;, &quot;HR 170-220 Minutes&quot;, &quot;Average Resting HR&quot;]) Next, we will need a function to collect all the data togother and place it into a data frame: #adds data to data frame def getBiometricData(myDF, myDate): totalDistance, veryActiveDistance, moderatleyActiveDistance, lightlyActiveDistance, veryActiveMinutes, fairlyActiveMinutes, lightlyActiveMinutes, sedentaryMinutes, floorsClimbed, daySteps = getActivities(myDate) sleepEfficiency, minutesAsleep = getSleep(myDate) HRrange30to100, HRrange100to140, HRrange140to170, HRrange170to220, avgRestingHR = getHeart(myDate) weight, BMI = getWeight(myDate) todaysData = {&quot;Date&quot; : myDate, &quot;Steps&quot; : daySteps, &quot;Floors Climbed&quot; : floorsClimbed, &quot;Total Miles&quot;: totalDistance, &quot;Lightly Active Miles&quot;: lightlyActiveDistance, &quot;Moderately Active Miles&quot; : moderatleyActiveDistance, &quot;Very Active Miles&quot; : veryActiveDistance, &quot;Sedentary Minutes&quot;: sedentaryMinutes, &quot;Lightly Active Minutes&quot;: lightlyActiveMinutes, &quot;Fairly Active Minutes&quot; : fairlyActiveMinutes, &quot;Very Active Minutes&quot; : veryActiveMinutes,&quot;HR 30-100 Minutes&quot; : HRrange30to100, &quot;HR 100-140 Minutes&quot;: HRrange100to140, &quot;HR 140-170 Minutes&quot; : HRrange140to170, &quot;HR 170-220 Minutes&quot; : HRrange170to220, &quot;Average Resting HR&quot;: avgRestingHR, &quot;Sleep Efficiency&quot; : sleepEfficiency, &quot;Weight&quot; : weight, &quot;Minutes Alseep&quot; : minutesAsleep, &quot;BMI&quot; : BMI} biometricDF = myDF.append(todaysData, ignore_index=True) return biometricDF And, finally, creating the database with todays data: biometricDF = getBiometricData(biometricDF, today) #append to data frame 8.6 Storing Data This process can be replicated each day so data must be stored appropriately. To start, we can export our data frame to a csv file and save the files to a directory like this (I created a new folder named bioDates to store all my Data): biometricDF.to_csv(&#39;./bioDates/&#39; + today + &#39;.csv&#39;) In the following chapters of this tutorial, we will learn how to concatenate the indiviudal daily csv files into one master file as well as storing the data into a a SQL database! "],
["working-in-bash.html", "Chapter 9 Working in Bash 9.1 Introduction 9.2 Working with Data using Bash 9.3 Bash Scripts", " Chapter 9 Working in Bash 9.1 Introduction Unix is simply a computer operating operating system. Bash, on the other hand, is a shell. Shells are command line interfaces where where you can communcate with the computer via certain commands. Lets explore some commands. Feel free to test these on your machine in a terminal. 9.1.1 Basic Commands 9.1.1.1 pwd The command ‘pwd’ will display the current working directory. Directories are file systems that contain references to other durectories and files. 9.1.1.2 ls In order to view the files contained within the directory, we can use the command ‘ls’. This will list the files and sub-directories in the current worrking directory 9.1.1.3 cd ‘cd’ stands for change directory and will change the working directory to a specified directory using a file path. By just entering cd, you will directed to your home directory 9.1.1.4 mkdir With the ‘mkdir’ command, a new directory will be created with the name we provide within the current working directory. 9.1.1.5 touch and nano The ‘touch’ command will create a new file within the current working directory. Heres and example pwd mkdir Example cd Example/ pwd touch exampleTextFile.txt ls ## /home/runner/work/wearables-book/wearables-book ## /home/runner/work/wearables-book/wearables-book/Example ## exampleTextFile.txt For more basic bash commands, refer to https://www.educative.io/blog/bash-shell-command-cheat-sheet! 9.2 Working with Data using Bash Bash is very powerful when working with data. Let’s explore an example of some data analysis using bash commands. First, we will retrieve some data using the ‘wget’ command. This command will dowload data from a URL and save it to the current durectory. For Mac users: If the wget command returns the error ‘wget: command not found’, then run ruby -e “$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)” followed by brew install wget This process installs Homebrew, which is a package manager for missing packages on macOS. wget https://raw.githubusercontent.com/fivethirtyeight/data/master/us-weather-history/KNYC.csv ## --2020-06-16 18:59:17-- https://raw.githubusercontent.com/fivethirtyeight/data/master/us-weather-history/KNYC.csv ## Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.208.133 ## Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.208.133|:443... connected. ## HTTP request sent, awaiting response... 200 OK ## Length: 20604 (20K) [text/plain] ## Saving to: ‘KNYC.csv.4’ ## ## 0K .......... .......... 100% 1.84M=0.01s ## ## 2020-06-16 18:59:17 (1.84 MB/s) - ‘KNYC.csv.4’ saved [20604/20604] Now, we can view the first n rows of the data. In this example, we will view the first five lines head -n5 KNYC.csv ## date,actual_mean_temp,actual_min_temp,actual_max_temp,average_min_temp,average_max_temp,record_min_temp,record_max_temp,record_min_temp_year,record_max_temp_year,actual_precipitation,average_precipitation,record_precipitation ## 2014-7-1,81,72,89,68,83,52,100,1943,1901,0.00,0.12,2.17 ## 2014-7-2,82,72,91,68,83,56,100,2001,1966,0.96,0.13,1.79 ## 2014-7-3,78,69,87,68,83,54,103,1933,1966,1.78,0.12,2.80 ## 2014-7-4,70,65,74,68,84,55,102,1986,1949,0.14,0.13,1.76 Another helpful way to view data is to save subsets of data to seperate files. Here we save the first 10 lines to a new file called short.csv. head -n10 KNYC.csv &gt;short.csv Now we can view the whole file using the ‘cat’ command. cat short.csv ## date,actual_mean_temp,actual_min_temp,actual_max_temp,average_min_temp,average_max_temp,record_min_temp,record_max_temp,record_min_temp_year,record_max_temp_year,actual_precipitation,average_precipitation,record_precipitation ## 2014-7-1,81,72,89,68,83,52,100,1943,1901,0.00,0.12,2.17 ## 2014-7-2,82,72,91,68,83,56,100,2001,1966,0.96,0.13,1.79 ## 2014-7-3,78,69,87,68,83,54,103,1933,1966,1.78,0.12,2.80 ## 2014-7-4,70,65,74,68,84,55,102,1986,1949,0.14,0.13,1.76 ## 2014-7-5,72,63,81,68,84,53,101,1979,1999,0.00,0.12,3.07 ## 2014-7-6,75,66,84,68,84,54,103,1979,2010,0.00,0.13,1.97 ## 2014-7-7,81,72,90,68,84,56,100,1914,2010,0.04,0.13,3.13 ## 2014-7-8,81,71,91,69,84,56,100,1894,1993,0.39,0.14,1.80 ## 2014-7-9,80,71,88,69,84,54,106,1963,1936,0.09,0.14,1.09 We can also view specifc columns from our data using ‘cut’. cut -d, -f1,4 short.csv ## date,actual_max_temp ## 2014-7-1,89 ## 2014-7-2,91 ## 2014-7-3,87 ## 2014-7-4,74 ## 2014-7-5,81 ## 2014-7-6,84 ## 2014-7-7,90 ## 2014-7-8,91 ## 2014-7-9,88 Next, lets look at a specific row by using the ‘grep’ command to search by date. grep 2015-2-23 KNYC.csv ## 2015-2-23,23,8,38,30,43,5,70,1889,1985,0.00,0.12,1.38 9.3 Bash Scripts Now that we have covered some of the basics of bash, let’s explore a powerful tool within bash called bash scripting. Writing bash srcipts is similar to any other program where each new line is a command with an intent to build upon previous computations. We can create files that will perform the tasks within. Consider this: If we want to write some bash commands that will write the time of day to a file we can do something like touch myDateFile.txt date &gt;&gt;myDateFile.txt running these commands each time we would like to write the date to the .txt file would begin to be tedius after time. Bash scripts provide an easy solution! First, we will create a new .sh file. touch myDateBash.sh Then, using a text editor, we can edit the file and enter our code to write the date to myDateFile.txt. Paste the following command into a terminal (be sure your working directory is the same directory as where you saved your bash file): vi myDateBash.sh You will be presented with a screen that looks like the following image. Then, type the letter i to enter “Insert Mode” and write in date &gt;&gt;myDateFile.txt. Then, click escape on your keyboard and then type “:wq”. You should now be back to a normal Terminal setting. Next, we need to set the file permisions. Paste “chmod +x myDateBash.sh” into the terminal. Great! Now the setup is complete and we can run the bash script to write the current date and time to. myDateFile.txt like this: ./myDateBash.sh Lastly, to view the contents of the date text file: cat myDateFile.txt For more information on Bash and scripting, refer to https://linuxconfig.org/bash-scripting-tutorial. "],
["tutorial-data-processing-with-bash.html", "Chapter 10 Tutorial - Data Processing with Bash", " Chapter 10 Tutorial - Data Processing with Bash Using the basics of bash and some more advanced commands we can now use the python script that we developed in the prevoius tutorial! Let’s start by creating a new bash script. We will call it bioBash.sh. touch bioBash.sh The first action we need to take is to run our python script from command line. Using a text editor, either vim or nano, write python /path/to/your/python/script in your bash script. This will run the python script! Next, we can need to change directories to the folder where we are stroing the data. In the previous tutorial section, I named this directory bioDates. Once again, using a text editor, write cd /path/to/your/biometric/data in bioBash.sh. Lastsly, we will need to concatenate all the individual dates into one master .csv. This can be done with the following line of code: awk &#39;FNR==1 &amp;&amp; NR!=1{next;}{print}&#39; *.csv &gt; bioFinal.csv. With this line, we concatenate all csv files into one master csv file called bioFinal.csv. "]
]
